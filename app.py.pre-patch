
# SustainaCore app.py — SMART v2
import os, re, time, json, requests
from collections import defaultdict
from flask import Flask, request, jsonify
from db_helper import top_k_by_vector

EMBED_DIM = int(os.getenv("EMBED_DIM", "384"))
OLLAMA = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434")
OLLAMA_EMBED_MODEL = os.getenv("OLLAMA_EMBED_MODEL", "all-minilm")

FUSION_TOPK_BASE = int(os.getenv("FUSION_TOPK_BASE", "8"))
FUSION_TOPK_MAX  = int(os.getenv("FUSION_TOPK_MAX", "24"))
RRF_K            = int(os.getenv("RRF_K", "60"))
MMR_LAMBDA       = float(os.getenv("MMR_LAMBDA", "0.7"))
DOC_CAP          = int(os.getenv("DOC_CAP", "3"))
CHUNKS_MAX       = int(os.getenv("CHUNKS_MAX", "12"))
CITES_MAX        = int(os.getenv("CITES_MAX", "6"))
LATENCY_BUDGET_MS= int(os.getenv("LATENCY_BUDGET_MS", "1200"))
RETURN_TOP_AS_ANSWER = os.getenv("RETURN_TOP_AS_ANSWER","1") == "1"

app = Flask(__name__)

def embed(text: str):
    text = (text or "").strip()
    if not text: return [0.0]*EMBED_DIM
    url = f"{OLLAMA}/api/embeddings"
    resp = requests.post(url, json={"model": OLLAMA_EMBED_MODEL, "prompt": text}, timeout=15)
    resp.raise_for_status()
    data = resp.json()
    vec = data.get("embedding") or (data.get("data") or [{}])[0].get("embedding")
    if not isinstance(vec, list): return [0.0]*EMBED_DIM
    if len(vec) > EMBED_DIM: vec = vec[:EMBED_DIM]
    if len(vec) < EMBED_DIM: vec = vec + [0.0]*(EMBED_DIM-len(vec))
    return vec

META_KEYS = ("ROLE:", "TASK:", "PREVIOUS ANSWER", "QUESTION TYPE", "CONTEXT TITLES:", "buttons to click", "What would you like to explore?")

def normalize_question(q: str):
    q0 = (q or "").strip()
    changed = False
    if any(k in q0 for k in META_KEYS):
        changed = True
        m = re.findall(r'([A-Z][^?]{3,}\?)', q0, flags=re.S)
        if m:
            q1 = m[-1].strip()
        else:
            q1 = re.sub(r'(?mi)^(ROLE|TASK|PREVIOUS ANSWER|QUESTION TYPE|CONTEXT TITLES).*$','',q0)
            q1 = re.sub(r'buttons to click.*','',q1, flags=re.I)
            q1 = re.sub(r'\s+',' ', q1).strip()
        q0 = q1 or "help"
    return q0, changed

ALIAS = {
    "tech 100": "TECH100", "tech-100": "TECH100", "ai governance & ethics index": "TECH100",
    "msft":"Microsoft","csco":"Cisco","aapl":"Apple","googl":"Alphabet","goog":"Alphabet","meta":"Meta",
    "google":"Alphabet","microsoft":"Microsoft","cisco":"Cisco","apple":"Apple","alphabet":"Alphabet","ibm":"IBM",
}

def detect_intent(q: str, ents):
    ql = q.lower()
    if re.search(r'\b(rank|ranking)\b', ql): return "rank"
    if re.search(r'\bmember(ship)?\b|\bpart of\b', ql): return "membership"
    if re.search(r'\bcompare|vs\.|versus|difference\b', ql): return "comparison"
    if re.search(r'\btrend|over time|history\b', ql): return "trend"
    if re.search(r'\bhow\b|\bwhy\b|\bsteps?\b', ql): return "howwhy"
    if re.search(r'\bpolicy|regulat|law|directive|act\b', ql): return "policy"
    if len(q.strip())<=2 and ents: return "overview"
    if (len(ents)==1) and (len(q.split())<=4): return "overview"
    if re.search(r'what is this website|what information is available', ql): return "about"
    return "general"

def extract_entities(q: str):
    ents = []
    for m in re.finditer(r'\b([A-Z][A-Za-z0-9&\.\-]{1,}(?: [A-Z][A-Za-z0-9&\.\-]{1,}){0,3})\b', q):
        s = m.group(1).strip()
        if s: ents.append(ALIAS.get(s.lower(), s))
    if "tech 100" in q.lower() or "tech-100" in q.lower(): ents.append("TECH100")
    seen=set(); out=[]
    for e in ents:
        if e not in seen:
            seen.add(e); out.append(e)
    return out[:5]

def make_variants(q: str, ents):
    vs=[q.strip()]
    qn=re.sub(r'\btech[-\s]?100\b','TECH100',q,flags=re.I)
    if qn!=q: vs.append(qn)
    vs.append(re.sub(r'[^\w\s]',' ',qn))
    seen=set(); out=[]
    for s in vs:
        s=s.strip()
        if s and s not in seen:
            seen.add(s); out.append(s)
    return out[:5]

def rrf_fuse(variant_results, k=RRF_K):
    from collections import defaultdict
    scores=defaultdict(float); bykey={}
    for res in variant_results:
        for rank,item in enumerate(res,1):
            key=(item.get("doc_id"),item.get("chunk_ix"))
            bykey[key]=item; scores[key]+=1.0/(k+rank)
    ranked=sorted(scores.items(), key=lambda kv: kv[1], reverse=True)
    return [bykey[k] for k,_ in ranked]

def _tok(s): 
    import re
    return set(re.findall(r'[A-Za-z0-9]{2,}', (s or "").lower()))

def mmr_select(cands, max_k=CHUNKS_MAX, lambda_=MMR_LAMBDA, per_doc=DOC_CAP):
    sel=[]; used=defaultdict(int)
    cand_tokens=[(_tok(c.get("chunk_text","")),i) for i,c in enumerate(cands)]
    while len(sel)<max_k and cands:
        best=None;best_score=-1;best_idx=None
        for idx,c in enumerate(cands):
            if used[c.get("doc_id")]>=per_doc: continue
            rel=1.0/(1.0+float(c.get("dist",0.0) or 0.0))
            if not sel: score=rel
            else:
                t_c=cand_tokens[idx][0]
                sim=max((len(t_c & _tok(s.get("chunk_text","")))/max(1,len(t_c|_tok(s.get("chunk_text","")))) for s in sel), default=0.0)
                score=lambda_*rel-(1.0-lambda_)*sim
            if score>best_score: best_score=score; best=c; best_idx=idx
        if best is None: break
        sel.append(best); used[best.get("doc_id")]+=1
        cands.pop(best_idx); cand_tokens.pop(best_idx)
    return sel

def retrieve(q: str):
    ents=extract_entities(q)
    variants=make_variants(q, ents)
    topk=FUSION_TOPK_BASE
    per_variant=[]
    for v in variants:
        vec=embed(v)
        rows=top_k_by_vector(vec, topk)
        per_variant.append(rows)
    fused=rrf_fuse(per_variant, k=RRF_K)
    if len(fused)<CHUNKS_MAX//2 and topk<FUSION_TOPK_MAX:
        topk=min(FUSION_TOPK_MAX, topk*2)
        per_variant=[]
        for v in variants:
            vec=embed(v); rows=top_k_by_vector(vec, topk); per_variant.append(rows)
        fused=rrf_fuse(per_variant, k=RRF_K)
    fused=mmr_select(fused[:max(32,FUSION_TOPK_MAX)], max_k=CHUNKS_MAX, lambda_=MMR_LAMBDA, per_doc=DOC_CAP)
    return {"entities": ents, "variants": variants, "chunks": fused, "k": topk}

def extract_quotes(chunks, limit_words=60):
    quotes=[]; total=0
    for i,c in enumerate(chunks,1):
        txt=(c.get("chunk_text") or "").strip()
        if not txt: continue
        parts=re.split(r'(?<=[.!?])\s+', txt)
        for p in parts[:2]:
            w=len(p.split())
            if w==0: continue
            if total + w > limit_words: break
            quotes.append((i, p.strip())); total+=w
        if total>=limit_words: break
    return quotes

def find_first(chunks, key):
    for c in chunks:
        t=(c.get("title") or "").lower()
        if key in t: return c
    return None

def parse_rank(chunk):
    if not chunk: return None
    t=(chunk.get("chunk_text") or "") + " " + (chunk.get("title") or "")
    m=re.search(r'\brank\s*(?:is\s*)?(?:#\s*)?(\d{1,3})\b', t, flags=re.I)
    if m: return m.group(1)
    if re.search(r'\branks?\s*first\b', t, flags=re.I): return "1"
    if re.search(r'\branks?\s*second\b', t, flags=re.I): return "2"
    if re.search(r'\branks?\s*third\b', t, flags=re.I): return "3"
    return None

def parse_asof(chunk):
    if not chunk: return None
    txt=(chunk.get("chunk_text") or "")
    m=re.search(r'(20\d{2}[-/]\d{2}|20\d{2}-\d{2}-\d{2}|[A-Za-z]{3,9}\s+20\d{2})', txt)
    return m.group(1) if m else None

def sources_block(chunks, maxn=CITES_MAX):
    seen=set(); src=[]
    for c in chunks:
        t=(c.get("title") or "").strip()
        if t and t not in seen:
            seen.add(t); src.append(t)
        if len(src)>=maxn: break
    return src

def compose_overview(entity, chunks, quotes):
    mem=find_first(chunks,"membership")
    rank=find_first(chunks,"rank")
    rnk=parse_rank(rank)
    asof=parse_asof(mem) or parse_asof(rank)
    lines=[]
    if mem: lines.append(f"TECH100 membership: Yes{f' (as of {asof})' if asof else ''}.")
    else:   lines.append("TECH100 membership: Not found in retrieved membership list.")
    if rnk: lines.append(f"Latest rank: {rnk}.")
    why=["[S{}] {}".format(i, q) for i,q in quotes[:4]]
    src=sources_block(chunks)
    out=[]
    out.append(f"{entity}: overview from SustainaCore’s knowledge base")
    out.extend("- "+w for w in lines)
    if why:
        out.append("Why this answer:")
        out.extend("- "+w for w in why)
    if src:
        out.append("Sources: " + "; ".join(src))
    return "\n".join(out)

def compose_answer(intent, q, entities, chunks, quotes):
    if intent=="about":
        return ("SustainaCore Assistant helps you explore the TECH100 AI Governance & Ethics Index and related ESG/AI sources.\n"
                "- Ask about a company’s TECH100 membership or latest rank.\n"
                "- Request a quick AI & ESG snapshot for any TECH100 company.\n"
                "- Data comes from Oracle Autonomous DB + Vector Search.\n"), "about"
    if intent=="overview" and entities:
        return compose_overview(entities[0], chunks, quotes), "overview"
    if intent in ("membership","rank") and entities:
        mem=find_first(chunks,"membership") if intent=="membership" else None
        rank=find_first(chunks,"rank")
        rnk=parse_rank(rank)
        asof=parse_asof(mem) or parse_asof(rank)
        lines=[]
        if intent=="membership":
            if mem: lines.append(f"Yes — {entities[0]} is in TECH100{f' (as of {asof})' if asof else ''}.")
            else:   lines.append(f"No evidence of {entities[0]} in TECH100 from retrieved membership context.")
        if intent=="rank":
            if rnk: lines.append(f"{entities[0]} latest TECH100 rank: {rnk}.")
            else:   lines.append("No clear rank found in retrieved context.")
        why=["[S{}] {}".format(i,q) for i,q in quotes[:4]]
        out="\n".join(lines + (["Why this answer:"]+[f"- {w}" for w in why] if why else []))
        src=sources_block(chunks)
        if src: out += "\nSources: " + "; ".join(src)
        return out, intent
    bullets=["[S{}] {}".format(i,q) for i,q in quotes[:6]]
    head="Here’s the best supported answer from the retrieved sources."
    out="\n".join([head] + (["Why this answer:"]+[f"- {b}" for b in bullets] if bullets else []))
    src=sources_block(chunks)
    if src: out += "\nSources: " + "; ".join(src)
    return out, "general"

class NormalizeMiddleware:
    def __init__(self, app): self.app=app
    def __call__(self, environ, start_response):
        if environ.get("PATH_INFO")=="/ask" and (environ.get("REQUEST_METHOD") or "").upper()=="POST":
            import io as _io
            try: size=int(environ.get("CONTENT_LENGTH") or "0")
            except Exception: size=0
            raw=environ["wsgi.input"].read(size) if size>0 else b""
            try: body=json.loads(raw.decode("utf-8") or "{}")
            except Exception: body={}
            q=body.get("question") or body.get("q") or ""
            norm, changed = normalize_question(q)
            if changed:
                body["question"]=norm
                raw=json.dumps(body, ensure_ascii=False).encode("utf-8")
                environ["CONTENT_LENGTH"]=str(len(raw))
                environ["wsgi.input"]=_io.BytesIO(raw)
                def _sr(status, headers, exc_info=None):
                    headers=list(headers); headers.append(("X-Question-Normalized","on"))
                    return start_response(status, headers, exc_info)
                return self.app(environ, _sr)
            else:
                environ["CONTENT_LENGTH"]=str(len(raw))
                environ["wsgi.input"]=_io.BytesIO(raw)
        return self.app(environ, start_response)

class OrchestrateMiddleware:
    def __init__(self, app): self.app=app
    def __call__(self, environ, start_response):
        path=environ.get("PATH_INFO",""); method=(environ.get("REQUEST_METHOD") or "GET").upper()
        if not (path=="/ask" and method=="POST"):
            return self.app(environ, start_response)

        import io as _io
        try: size=int(environ.get("CONTENT_LENGTH") or "0")
        except Exception: size=0
        body=environ["wsgi.input"].read(size) if size>0 else b""
        try: req=json.loads(body.decode("utf-8") or "{}")
        except Exception: req={}
        q=(req.get("question") or req.get("q") or "").strip()
        if not q:
            return self.app(environ, start_response)

        t0=time.time()
        retrieval=retrieve(q)
        entities=retrieval["entities"]
        chunks=retrieval["chunks"]
        quotes=extract_quotes(chunks, limit_words=60)
        intent=detect_intent(q, entities)

        if (not chunks) or (entities and not any(entities[0].lower() in ( (c.get("title") or "").lower() + (c.get("chunk_text") or "").lower() ) for c in chunks)):
            ans=("I couldn’t find that in SustainaCore’s knowledge base.\n"
                 "- Scope: TECH100 companies and ESG/AI governance sources.\n"
                 "- Tip: try a company name or ask about TECH100 membership or latest rank.")
            payload={"answer": ans, "contexts": chunks, "mode":"simple"}
            data=json.dumps(payload, ensure_ascii=False).encode("utf-8")
            hdrs=[("Content-Type","application/json"),
                  ("X-Intent", intent), ("X-K", str(retrieval["k"])),
                  ("X-RRF","on"), ("X-MMR", str(MMR_LAMBDA)),
                  ("X-Loops","1"), ("X-BudgetMs", str(int((time.time()-t0)*1000))),
                  ("X-Answer-Shape","not-found"), ("Content-Length", str(len(data)))]
            start_response("200 OK", hdrs)
            return [data]

        answer, shape = compose_answer(intent, q, entities, chunks, quotes)
        payload={"answer": answer, "contexts": chunks, "mode":"simple"}
        data=json.dumps(payload, ensure_ascii=False).encode("utf-8")
        hdrs=[("Content-Type","application/json"),
              ("X-Intent", intent), ("X-K", str(retrieval["k"])),
              ("X-RRF","on"), ("X-MMR", str(MMR_LAMBDA)),
              ("X-Loops","1"), ("X-BudgetMs", str(int((time.time()-t0)*1000))),
              ("X-Answer-Shape", shape), ("Content-Length", str(len(data)))]
        start_response("200 OK", hdrs)
        return [data]

@app.route("/healthz")
def healthz():
    return jsonify({"ok": True, "ts": time.time()})

@app.route("/ask", methods=["POST"])
def ask():
    try:
        body = request.get_json(force=True) or {}
        q = (body.get("question") or body.get("q") or "").strip()
        if not q: return jsonify({"error":"question is required"}), 400
        vec = embed(q); rows = top_k_by_vector(vec, max(1, FUSION_TOPK_BASE))
        ans = rows[0]["chunk_text"] if rows else "No context found."
        if RETURN_TOP_AS_ANSWER:
            return jsonify({"answer": ans, "contexts": rows, "mode":"simple"})
        else:
            return jsonify({"answer": "No generator configured.", "contexts": rows, "mode":"simple"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Install middlewares
app.wsgi_app = NormalizeMiddleware(app.wsgi_app)
app.wsgi_app = OrchestrateMiddleware(app.wsgi_app)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
